{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0juDZ1IWKNC",
        "outputId": "c6eee7eb-4698-4358-afef-4bed2c42f680"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/the-verdict.txt', <http.client.HTTPMessage at 0x7e4528c229d0>)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import urllib.request\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        "       \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        "       \"the-verdict.txt\")\n",
        "file_path = \"/content/the-verdict.txt\"\n",
        "urllib.request.urlretrieve(url, file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "print(\"Total number of character:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iowAVk7SWn7W",
        "outputId": "8ef8964c-1531-4372-d97d-ba56b37c595b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of character: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"Hello, World. This is a test\"\n",
        "result = re.split(r'(\\s)', text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9aMP1xmXFTX",
        "outputId": "9e2aa650-bd4f-4d8a-f083-340ef36456ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello,', ' ', 'World.', ' ', 'This', ' ', 'is', ' ', 'a', ' ', 'test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = re.split(f'([,.]|\\s)', text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpyecxvYXxoo",
        "outputId": "1836f7af-462d-4cdf-c1ab-ce9527cda6ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', '', ' ', 'World', '.', '', ' ', 'This', ' ', 'is', ' ', 'a', ' ', 'test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = [item for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOsywhKnYLs-",
        "outputId": "22be0479-a932-41d8-9109-1b8eb7089ac6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'World', '.', 'This', 'is', 'a', 'test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, world. Is this-- a test?\"\n",
        "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "result = [item.strip() for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txcm66yAYefV",
        "outputId": "a8675abb-4757-4f59-cf8f-22f54c4925b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
        "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "print(preprocessed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yROWIvGaZVrN",
        "outputId": "322dfb30-59d2-4660-e828-cd9d71285f8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself', 'in', 'a', 'villa', 'on', 'the', 'Riviera', '.', '(', 'Though', 'I', 'rather', 'thought', 'it', 'would', 'have', 'been', 'Rome', 'or', 'Florence', '.', ')', '\"', 'The', 'height', 'of', 'his', 'glory', '\"', '--', 'that', 'was', 'what', 'the', 'women', 'called', 'it', '.', 'I', 'can', 'hear', 'Mrs', '.', 'Gideon', 'Thwing', '--', 'his', 'last', 'Chicago', 'sitter', '--', 'deploring', 'his', 'unaccountable', 'abdication', '.', '\"', 'Of', 'course', 'it', \"'\", 's', 'going', 'to', 'send', 'the', 'value', 'of', 'my', 'picture', \"'\", 'way', 'up', ';', 'but', 'I', 'don', \"'\", 't', 'think', 'of', 'that', ',', 'Mr', '.', 'Rickham', '--', 'the', 'loss', 'to', 'Arrt', 'is', 'all', 'I', 'think', 'of', '.', '\"', 'The', 'word', ',', 'on', 'Mrs', '.', 'Thwing', \"'\", 's', 'lips', ',', 'multiplied', 'its', '_', 'rs', '_', 'as', 'though', 'they', 'were', 'reflected', 'in', 'an', 'endless', 'vista', 'of', 'mirrors', '.', 'And', 'it', 'was', 'not', 'only', 'the', 'Mrs', '.', 'Thwings', 'who', 'mourned', '.', 'Had', 'not', 'the', 'exquisite', 'Hermia', 'Croft', ',', 'at', 'the', 'last', 'Grafton', 'Gallery', 'show', ',', 'stopped', 'me', 'before', 'Gisburn', \"'\", 's', '\"', 'Moon-dancers', '\"', 'to', 'say', ',', 'with', 'tears', 'in', 'her', 'eyes', ':', '\"', 'We', 'shall', 'not', 'look', 'upon', 'its', 'like', 'again', '\"', '?', 'Well', '!', '--', 'even', 'through', 'the', 'prism', 'of', 'Hermia', \"'\", 's', 'tears', 'I', 'felt', 'able', 'to', 'face', 'the', 'fact', 'with', 'equanimity', '.', 'Poor', 'Jack', 'Gisburn', '!', 'The', 'women', 'had', 'made', 'him', '--', 'it', 'was', 'fitting', 'that', 'they', 'should', 'mourn', 'him', '.', 'Among', 'his', 'own', 'sex', 'fewer', 'regrets', 'were', 'heard', ',', 'and', 'in', 'his', 'own', 'trade', 'hardly', 'a', 'murmur', '.', 'Professional', 'jealousy', '?', 'Perhaps', '.', 'If', 'it', 'were', ',', 'the', 'honour', 'of', 'the', 'craft', 'was', 'vindicated', 'by', 'little', 'Claude', 'Nutley', ',', 'who', ',', 'in', 'all', 'good', 'faith', ',', 'brought', 'out', 'in', 'the', 'Burlington', 'a', 'very', 'handsome', '\"', 'obituary', '\"', 'on', 'Jack', '--', 'one', 'of', 'those', 'showy', 'articles', 'stocked', 'with', 'random', 'technicalities', 'that', 'I', 'have', 'heard', '(', 'I', 'won', \"'\", 't', 'say', 'by', 'whom', ')', 'compared', 'to', 'Gisburn', \"'\", 's', 'painting', '.', 'And', 'so', '--', 'his', 'resolve', 'being', 'apparently', 'irrevocable', '--', 'the', 'discussion', 'gradually', 'died', 'out', ',', 'and', ',', 'as', 'Mrs', '.', 'Thwing', 'had', 'predicted', ',', 'the', 'price', 'of', '\"', 'Gisburns', '\"', 'went', 'up', '.', 'It', 'was', 'not', 'till', 'three', 'years', 'later', 'that', ',', 'in', 'the', 'course', 'of', 'a', 'few', 'weeks', \"'\", 'idling', 'on', 'the', 'Riviera', ',', 'it', 'suddenly', 'occurred', 'to', 'me', 'to', 'wonder', 'why', 'Gisburn', 'had', 'given', 'up', 'his', 'painting', '.', 'On', 'reflection', ',', 'it', 'really', 'was', 'a', 'tempting', 'problem', '.', 'To', 'accuse', 'his', 'wife', 'would', 'have', 'been', 'too', 'easy', '--', 'his', 'fair', 'sitters', 'had', 'been', 'denied', 'the', 'solace', 'of', 'saying', 'that', 'Mrs', '.', 'Gisburn', 'had', '\"', 'dragged', 'him', 'down', '.', '\"', 'For', 'Mrs', '.', 'Gisburn', '--', 'as', 'such', '--', 'had', 'not', 'existed', 'till', 'nearly', 'a', 'year', 'after', 'Jack', \"'\", 's', 'resolve', 'had', 'been', 'taken', '.', 'It', 'might', 'be', 'that', 'he', 'had', 'married', 'her', '--', 'since', 'he', 'liked', 'his', 'ease', '--', 'because', 'he', 'didn', \"'\", 't', 'want', 'to', 'go', 'on', 'painting', ';', 'but', 'it', 'would', 'have', 'been', 'hard', 'to', 'prove', 'that', 'he', 'had', 'given', 'up', 'his', 'painting', 'because', 'he', 'had', 'married', 'her', '.', 'Of', 'course', ',', 'if', 'she', 'had', 'not', 'dragged', 'him', 'down', ',', 'she', 'had', 'equally', ',', 'as', 'Miss', 'Croft', 'contended', ',', 'failed', 'to', '\"', 'lift', 'him', 'up', '\"', '--', 'she', 'had', 'not', 'led', 'him', 'back', 'to', 'the', 'easel', '.', 'To', 'put', 'the', 'brush', 'into', 'his', 'hand', 'again', '--', 'what', 'a', 'vocation', 'for', 'a', 'wife', '!', 'But', 'Mrs', '.', 'Gisburn', 'appeared', 'to', 'have', 'disdained', 'it', '--', 'and', 'I', 'felt', 'it', 'might', 'be', 'interesting', 'to', 'find', 'out', 'why', '.', 'The', 'desultory', 'life', 'of', 'the', 'Riviera', 'lends', 'itself', 'to', 'such', 'purely', 'academic', 'speculations', ';', 'and', 'having', ',', 'on', 'my', 'way', 'to', 'Monte', 'Carlo', ',', 'caught', 'a', 'glimpse', 'of', 'Jack', \"'\", 's', 'balustraded', 'terraces', 'between', 'the', 'pines', ',', 'I', 'had', 'myself', 'borne', 'thither', 'the', 'next', 'day', '.', 'I', 'found', 'the', 'couple', 'at', 'tea', 'beneath', 'their', 'palm-trees', ';', 'and', 'Mrs', '.', 'Gisburn', \"'\", 's', 'welcome', 'was', 'so', 'genial', 'that', ',', 'in', 'the', 'ensuing', 'weeks', ',', 'I', 'claimed', 'it', 'frequently', '.', 'It', 'was', 'not', 'that', 'my', 'hostess', 'was', '\"', 'interesting', '\"', ':', 'on', 'that', 'point', 'I', 'could', 'have', 'given', 'Miss', 'Croft', 'the', 'fullest', 'reassurance', '.', 'It', 'was', 'just', 'because', 'she', 'was', '_', 'not', '_', 'interesting', '--', 'if', 'I', 'may', 'be', 'pardoned', 'the', 'bull', '--', 'that', 'I', 'found', 'her', 'so', '.', 'For', 'Jack', ',', 'all', 'his', 'life', ',', 'had', 'been', 'surrounded', 'by', 'interesting', 'women', ':', 'they', 'had', 'fostered', 'his', 'art', ',', 'it', 'had', 'been', 'reared', 'in', 'the', 'hot-house', 'of', 'their', 'adulation', '.', 'And', 'it', 'was', 'therefore', 'instructive', 'to', 'note', 'what', 'effect', 'the', '\"', 'deadening', 'atmosphere', 'of', 'mediocrity', '\"', '(', 'I', 'quote', 'Miss', 'Croft', ')', 'was', 'having', 'on', 'him', '.', 'I', 'have', 'mentioned', 'that', 'Mrs', '.', 'Gisburn', 'was', 'rich', ';', 'and', 'it', 'was', 'immediately', 'perceptible', 'that', 'her', 'husband', 'was', 'extracting', 'from', 'this', 'circumstance', 'a', 'delicate', 'but', 'substantial', 'satisfaction', '.', 'It', 'is', ',', 'as', 'a', 'rule', ',', 'the', 'people', 'who', 'scorn', 'money', 'who', 'get', 'most', 'out', 'of', 'it', ';', 'and', 'Jack', \"'\", 's', 'elegant', 'disdain', 'of', 'his', 'wife', \"'\", 's', 'big', 'balance', 'enabled', 'him', ',', 'with', 'an', 'appearance', 'of', 'perfect', 'good-breeding', ',', 'to', 'transmute', 'it', 'into', 'objects', 'of', 'art', 'and', 'luxury', '.', 'To', 'the', 'latter', ',', 'I', 'must', 'add', ',', 'he', 'remained', 'relatively', 'indifferent', ';', 'but', 'he', 'was', 'buying', 'Renaissance', 'bronzes', 'and', 'eighteenth-century', 'pictures', 'with', 'a', 'discrimination', 'that', 'bespoke', 'the', 'amplest', 'resources', '.', '\"', 'Money', \"'\", 's', 'only', 'excuse', 'is', 'to', 'put', 'beauty', 'into', 'circulation', ',', '\"', 'was', 'one', 'of', 'the', 'axioms', 'he', 'laid', 'down', 'across', 'the', 'Sevres', 'and', 'silver', 'of', 'an', 'exquisitely', 'appointed', 'luncheon-table', ',', 'when', ',', 'on', 'a', 'later', 'day', ',', 'I', 'had', 'again', 'run', 'over', 'from', 'Monte', 'Carlo', ';', 'and', 'Mrs', '.', 'Gisburn', ',', 'beaming', 'on', 'him', ',', 'added', 'for', 'my', 'enlightenment', ':', '\"', 'Jack', 'is', 'so', 'morbidly', 'sensitive', 'to', 'every', 'form', 'of', 'beauty', '.', '\"', 'Poor', 'Jack', '!', 'It', 'had', 'always', 'been', 'his', 'fate', 'to', 'have', 'women', 'say', 'such', 'things', 'of', 'him', ':', 'the', 'fact', 'should', 'be', 'set', 'down', 'in', 'extenuation', '.', 'What', 'struck', 'me', 'now', 'was', 'that', ',', 'for', 'the', 'first', 'time', ',', 'he', 'resented', 'the', 'tone', '.', 'I', 'had', 'seen', 'him', ',', 'so', 'often', ',', 'basking', 'under', 'similar', 'tributes', '--', 'was', 'it', 'the', 'conjugal', 'note', 'that', 'robbed', 'them', 'of', 'their', 'savour', '?', 'No', '--', 'for', ',', 'oddly', 'enough', ',', 'it', 'became', 'apparent', 'that', 'he', 'was', 'fond', 'of', 'Mrs', '.', 'Gisburn', '--', 'fond', 'enough', 'not', 'to', 'see', 'her', 'absurdity', '.', 'It', 'was', 'his', 'own', 'absurdity', 'he', 'seemed', 'to', 'be', 'wincing', 'under', '--', 'his', 'own', 'attitude', 'as', 'an', 'object', 'for', 'garlands', 'and', 'incense', '.', '\"', 'My', 'dear', ',', 'since', 'I', \"'\", 've', 'chucked', 'painting', 'people', 'don', \"'\", 't', 'say', 'that', 'stuff', 'about', 'me', '--', 'they', 'say', 'it', 'about', 'Victor', 'Grindle', ',', '\"', 'was', 'his', 'only', 'protest', ',', 'as', 'he', 'rose', 'from', 'the', 'table', 'and', 'strolled', 'out', 'onto', 'the', 'sunlit', 'terrace', '.', 'I', 'glanced', 'after', 'him', ',', 'struck', 'by', 'his', 'last', 'word', '.', 'Victor', 'Grindle', 'was', ',', 'in', 'fact', ',', 'becoming', 'the', 'man', 'of', 'the', 'moment', '--', 'as', 'Jack', 'himself', ',', 'one', 'might', 'put', 'it', ',', 'had', 'been', 'the', 'man', 'of', 'the', 'hour', '.', 'The', 'younger', 'artist', 'was', 'said', 'to', 'have', 'formed', 'himself', 'at', 'my', 'friend', \"'\", 's', 'feet', ',', 'and', 'I', 'wondered', 'if', 'a', 'tinge', 'of', 'jealousy', 'underlay', 'the', 'latter', \"'\", 's', 'mysterious', 'abdication', '.', 'But', 'no', '--', 'for', 'it', 'was', 'not', 'till', 'after', 'that', 'event', 'that', 'the', '_', 'rose', 'Dubarry', '_', 'drawing-rooms', 'had', 'begun', 'to', 'display', 'their', '\"', 'Grindles', '.', '\"', 'I', 'turned', 'to', 'Mrs', '.', 'Gisburn', ',', 'who', 'had', 'lingered', 'to', 'give', 'a', 'lump', 'of', 'sugar', 'to', 'her', 'spaniel', 'in', 'the', 'dining-room', '.', '\"', 'Why', '_', 'has', '_', 'he', 'chucked', 'painting', '?', '\"', 'I', 'asked', 'abruptly', '.', 'She', 'raised', 'her', 'eyebrows', 'with', 'a', 'hint', 'of', 'good-humoured', 'surprise', '.', '\"', 'Oh', ',', 'he', 'doesn', \"'\", 't', '_', 'have', '_', 'to', 'now', ',', 'you', 'know', ';', 'and', 'I', 'want', 'him', 'to', 'enjoy', 'himself', ',', '\"', 'she', 'said', 'quite', 'simply', '.', 'I', 'looked', 'about', 'the', 'spacious', 'white-panelled', 'room', ',', 'with', 'its', '_', 'famille-verte', '_', 'vases', 'repeating', 'the', 'tones', 'of', 'the', 'pale', 'damask', 'curtains', ',', 'and', 'its', 'eighteenth-century', 'pastels', 'in', 'delicate', 'faded', 'frames', '.', '\"', 'Has', 'he', 'chucked', 'his', 'pictures', 'too', '?', 'I', 'haven', \"'\", 't', 'seen', 'a', 'single', 'one', 'in', 'the', 'house', '.', '\"', 'A', 'slight', 'shade', 'of', 'constraint', 'crossed', 'Mrs', '.', 'Gisburn', \"'\", 's', 'open', 'countenance', '.', '\"', 'It', \"'\", 's', 'his', 'ridiculous', 'modesty', ',', 'you', 'know', '.', 'He', 'says', 'they', \"'\", 're', 'not', 'fit', 'to', 'have', 'about', ';', 'he', \"'\", 's', 'sent', 'them', 'all', 'away', 'except', 'one', '--', 'my', 'portrait', '--', 'and', 'that', 'I', 'have', 'to', 'keep', 'upstairs', '.', '\"', 'His', 'ridiculous', 'modesty', '--', 'Jack', \"'\", 's', 'modesty', 'about', 'his', 'pictures', '?', 'My', 'curiosity', 'was', 'growing', 'like', 'the', 'bean-stalk', '.', 'I', 'said', 'persuasively', 'to', 'my', 'hostess', ':', '\"', 'I', 'must', 'really', 'see', 'your', 'portrait', ',', 'you', 'know', '.', '\"', 'She', 'glanced', 'out', 'almost', 'timorously', 'at', 'the', 'terrace', 'where', 'her', 'husband', ',', 'lounging', 'in', 'a', 'hooded', 'chair', ',', 'had', 'lit', 'a', 'cigar', 'and', 'drawn', 'the', 'Russian', 'deerhound', \"'\", 's', 'head', 'between', 'his', 'knees', '.', '\"', 'Well', ',', 'come', 'while', 'he', \"'\", 's', 'not', 'looking', ',', '\"', 'she', 'said', ',', 'with', 'a', 'laugh', 'that', 'tried', 'to', 'hide', 'her', 'nervousness', ';', 'and', 'I', 'followed', 'her', 'between', 'the', 'marble', 'Emperors', 'of', 'the', 'hall', ',', 'and', 'up', 'the', 'wide', 'stairs', 'with', 'terra-cotta', 'nymphs', 'poised', 'among', 'flowers', 'at', 'each', 'landing', '.', 'In', 'the', 'dimmest', 'corner', 'of', 'her', 'boudoir', ',', 'amid', 'a', 'profusion', 'of', 'delicate', 'and', 'distinguished', 'objects', ',', 'hung', 'one', 'of', 'the', 'familiar', 'oval', 'canvases', ',', 'in', 'the', 'inevitable', 'garlanded', 'frame', '.', 'The', 'mere', 'outline', 'of', 'the', 'frame', 'called', 'up', 'all', 'Gisburn', \"'\", 's', 'past', '!', 'Mrs', '.', 'Gisburn', 'drew', 'back', 'the', 'window-curtains', ',', 'moved', 'aside', 'a', '_', 'jardiniere', '_', 'full', 'of', 'pink', 'azaleas', ',', 'pushed', 'an', 'arm-chair', 'away', ',', 'and', 'said', ':', '\"', 'If', 'you', 'stand', 'here', 'you', 'can', 'just', 'manage', 'to', 'see', 'it', '.', 'I', 'had', 'it', 'over', 'the', 'mantel-piece', ',', 'but', 'he', 'wouldn', \"'\", 't', 'let', 'it', 'stay', '.', '\"', 'Yes', '--', 'I', 'could', 'just', 'manage', 'to', 'see', 'it', '--', 'the', 'first', 'portrait', 'of', 'Jack', \"'\", 's', 'I', 'had', 'ever', 'had', 'to', 'strain', 'my', 'eyes', 'over', '!', 'Usually', 'they', 'had', 'the', 'place', 'of', 'honour', '--', 'say', 'the', 'central', 'panel', 'in', 'a', 'pale', 'yellow', 'or', '_', 'rose', 'Dubarry', '_', 'drawing-room', ',', 'or', 'a', 'monumental', 'easel', 'placed', 'so', 'that', 'it', 'took', 'the', 'light', 'through', 'curtains', 'of', 'old', 'Venetian', 'point', '.', 'The', 'more', 'modest', 'place', 'became', 'the', 'picture', 'better', ';', 'yet', ',', 'as', 'my', 'eyes', 'grew', 'accustomed', 'to', 'the', 'half-light', ',', 'all', 'the', 'characteristic', 'qualities', 'came', 'out', '--', 'all', 'the', 'hesitations', 'disguised', 'as', 'audacities', ',', 'the', 'tricks', 'of', 'prestidigitation', 'by', 'which', ',', 'with', 'such', 'consummate', 'skill', ',', 'he', 'managed', 'to', 'divert', 'attention', 'from', 'the', 'real', 'business', 'of', 'the', 'picture', 'to', 'some', 'pretty', 'irrelevance', 'of', 'detail', '.', 'Mrs', '.', 'Gisburn', ',', 'presenting', 'a', 'neutral', 'surface', 'to', 'work', 'on', '--', 'forming', ',', 'as', 'it', 'were', ',', 'so', 'inevitably', 'the', 'background', 'of', 'her', 'own', 'picture', '--', 'had', 'lent', 'herself', 'in', 'an', 'unusual', 'degree', 'to', 'the', 'display', 'of', 'this', 'false', 'virtuosity', '.', 'The', 'picture', 'was', 'one', 'of', 'Jack', \"'\", 's', '\"', 'strongest', ',', '\"', 'as', 'his', 'admirers', 'would', 'have', 'put', 'it', '--', 'it', 'represented', ',', 'on', 'his', 'part', ',', 'a', 'swelling', 'of', 'muscles', ',', 'a', 'congesting', 'of', 'veins', ',', 'a', 'balancing', ',', 'straddling', 'and', 'straining', ',', 'that', 'reminded', 'one', 'of', 'the', 'circus-clown', \"'\", 's', 'ironic', 'efforts', 'to', 'lift', 'a', 'feather', '.', 'It', 'met', ',', 'in', 'short', ',', 'at', 'every', 'point', 'the', 'demand', 'of', 'lovely', 'woman', 'to', 'be', 'painted', '\"', 'strongly', '\"', 'because', 'she', 'was', 'tired', 'of', 'being', 'painted', '\"', 'sweetly', '\"', '--', 'and', 'yet', 'not', 'to', 'lose', 'an', 'atom', 'of', 'the', 'sweetness', '.', '\"', 'It', \"'\", 's', 'the', 'last', 'he', 'painted', ',', 'you', 'know', ',', '\"', 'Mrs', '.', 'Gisburn', 'said', 'with', 'pardonable', 'pride', '.', '\"', 'The', 'last', 'but', 'one', ',', '\"', 'she', 'corrected', 'herself', '--', '\"', 'but', 'the', 'other', 'doesn', \"'\", 't', 'count', ',', 'because', 'he', 'destroyed', 'it', '.', '\"', '\"', 'Destroyed', 'it', '?', '\"', 'I', 'was', 'about', 'to', 'follow', 'up', 'this', 'clue', 'when', 'I', 'heard', 'a', 'footstep', 'and', 'saw', 'Jack', 'himself', 'on', 'the', 'threshold', '.', 'As', 'he', 'stood', 'there', ',', 'his', 'hands', 'in', 'the', 'pockets', 'of', 'his', 'velveteen', 'coat', ',', 'the', 'thin', 'brown', 'waves', 'of', 'hair', 'pushed', 'back', 'from', 'his', 'white', 'forehead', ',', 'his', 'lean', 'sunburnt', 'cheeks', 'furrowed', 'by', 'a', 'smile', 'that', 'lifted', 'the', 'tips', 'of', 'a', 'self-confident', 'moustache', ',', 'I', 'felt', 'to', 'what', 'a', 'degree', 'he', 'had', 'the', 'same', 'quality', 'as', 'his', 'pictures', '--', 'the', 'quality', 'of', 'looking', 'cleverer', 'than', 'he', 'was', '.', 'His', 'wife', 'glanced', 'at', 'him', 'deprecatingly', ',', 'but', 'his', 'eyes', 'travelled', 'past', 'her', 'to', 'the', 'portrait', '.', '\"', 'Mr', '.', 'Rickham', 'wanted', 'to', 'see', 'it', ',', '\"', 'she', 'began', ',', 'as', 'if', 'excusing', 'herself', '.', 'He', 'shrugged', 'his', 'shoulders', ',', 'still', 'smiling', '.', '\"', 'Oh', ',', 'Rickham', 'found', 'me', 'out', 'long', 'ago', ',', '\"', 'he', 'said', 'lightly', ';', 'then', ',', 'passing', 'his', 'arm', 'through', 'mine', ':', '\"', 'Come', 'and', 'see', 'the', 'rest', 'of', 'the', 'house', '.', '\"', 'He', 'showed', 'it', 'to', 'me', 'with', 'a', 'kind', 'of', 'naive', 'suburban', 'pride', ':', 'the', 'bath-rooms', ',', 'the', 'speaking-tubes', ',', 'the', 'dress-closets', ',', 'the', 'trouser-presses', '--', 'all', 'the', 'complex', 'simplifications', 'of', 'the', 'millionaire', \"'\", 's', 'domestic', 'economy', '.', 'And', 'whenever', 'my', 'wonder', 'paid', 'the', 'expected', 'tribute', 'he', 'said', ',', 'throwing', 'out', 'his', 'chest', 'a', 'little', ':', '\"', 'Yes', ',', 'I', 'really', 'don', \"'\", 't', 'see', 'how', 'people', 'manage', 'to', 'live', 'without', 'that', '.', '\"', 'Well', '--', 'it', 'was', 'just', 'the', 'end', 'one', 'might', 'have', 'foreseen', 'for', 'him', '.', 'Only', 'he', 'was', ',', 'through', 'it', 'all', 'and', 'in', 'spite', 'of', 'it', 'all', '--', 'as', 'he', 'had', 'been', 'through', ',', 'and', 'in', 'spite', 'of', ',', 'his', 'pictures', '--', 'so', 'handsome', ',', 'so', 'charming', ',', 'so', 'disarming', ',', 'that', 'one', 'longed', 'to', 'cry', 'out', ':', '\"', 'Be', 'dissatisfied', 'with', 'your', 'leisure', '!', '\"', 'as', 'once', 'one', 'had', 'longed', 'to', 'say', ':', '\"', 'Be', 'dissatisfied', 'with', 'your', 'work', '!', '\"', 'But', ',', 'with', 'the', 'cry', 'on', 'my', 'lips', ',', 'my', 'diagnosis', 'suffered', 'an', 'unexpected', 'check', '.', '\"', 'This', 'is', 'my', 'own', 'lair', ',', '\"', 'he', 'said', ',', 'leading', 'me', 'into', 'a', 'dark', 'plain', 'room', 'at', 'the', 'end', 'of', 'the', 'florid', 'vista', '.', 'It', 'was', 'square', 'and', 'brown', 'and', 'leathery', ':', 'no', '\"', 'effects', '\"', ';', 'no', 'bric-a-brac', ',', 'none', 'of', 'the', 'air', 'of', 'posing', 'for', 'reproduction', 'in', 'a', 'picture', 'weekly', '--', 'above', 'all', ',', 'no', 'least', 'sign', 'of', 'ever', 'having', 'been', 'used', 'as', 'a', 'studio', '.', 'The', 'fact', 'brought', 'home', 'to', 'me', 'the', 'absolute', 'finality', 'of', 'Jack', \"'\", 's', 'break', 'with', 'his', 'old', 'life', '.', '\"', 'Don', \"'\", 't', 'you', 'ever', 'dabble', 'with', 'paint', 'any', 'more', '?', '\"', 'I', 'asked', ',', 'still', 'looking', 'about', 'for', 'a', 'trace', 'of', 'such', 'activity', '.', '\"', 'Never', ',', '\"', 'he', 'said', 'briefly', '.', '\"', 'Or', 'water-colour', '--', 'or', 'etching', '?', '\"', 'His', 'confident', 'eyes', 'grew', 'dim', ',', 'and', 'his', 'cheeks', 'paled', 'a', 'little', 'under', 'their', 'handsome', 'sunburn', '.', '\"', 'Never', 'think', 'of', 'it', ',', 'my', 'dear', 'fellow', '--', 'any', 'more', 'than', 'if', 'I', \"'\", 'd', 'never', 'touched', 'a', 'brush', '.', '\"', 'And', 'his', 'tone', 'told', 'me', 'in', 'a', 'flash', 'that', 'he', 'never', 'thought', 'of', 'anything', 'else', '.', 'I', 'moved', 'away', ',', 'instinctively', 'embarrassed', 'by', 'my', 'unexpected', 'discovery', ';', 'and', 'as', 'I', 'turned', ',', 'my', 'eye', 'fell', 'on', 'a', 'small', 'picture', 'above', 'the', 'mantel-piece', '--', 'the', 'only', 'object', 'breaking', 'the', 'plain', 'oak', 'panelling', 'of', 'the', 'room', '.', '\"', 'Oh', ',', 'by', 'Jove', '!', '\"', 'I', 'said', '.', 'It', 'was', 'a', 'sketch', 'of', 'a', 'donkey', '--', 'an', 'old', 'tired', 'donkey', ',', 'standing', 'in', 'the', 'rain', 'under', 'a', 'wall', '.', '\"', 'By', 'Jove', '--', 'a', 'Stroud', '!', '\"', 'I', 'cried', '.', 'He', 'was', 'silent', ';', 'but', 'I', 'felt', 'him', 'close', 'behind', 'me', ',', 'breathing', 'a', 'little', 'quickly', '.', '\"', 'What', 'a', 'wonder', '!', 'Made', 'with', 'a', 'dozen', 'lines', '--', 'but', 'on', 'everlasting', 'foundations', '.', 'You', 'lucky', 'chap', ',', 'where', 'did', 'you', 'get', 'it', '?', '\"', 'He', 'answered', 'slowly', ':', '\"', 'Mrs', '.', 'Stroud', 'gave', 'it', 'to', 'me', '.', '\"', '\"', 'Ah', '--', 'I', 'didn', \"'\", 't', 'know', 'you', 'even', 'knew', 'the', 'Strouds', '.', 'He', 'was', 'such', 'an', 'inflexible', 'hermit', '.', '\"', '\"', 'I', 'didn', \"'\", 't', '--', 'till', 'after', '.', '.', '.', '.', 'She', 'sent', 'for', 'me', 'to', 'paint', 'him', 'when', 'he', 'was', 'dead', '.', '\"', '\"', 'When', 'he', 'was', 'dead', '?', 'You', '?', '\"', 'I', 'must', 'have', 'let', 'a', 'little', 'too', 'much', 'amazement', 'escape', 'through', 'my', 'surprise', ',', 'for', 'he', 'answered', 'with', 'a', 'deprecating', 'laugh', ':', '\"', 'Yes', '--', 'she', \"'\", 's', 'an', 'awful', 'simpleton', ',', 'you', 'know', ',', 'Mrs', '.', 'Stroud', '.', 'Her', 'only', 'idea', 'was', 'to', 'have', 'him', 'done', 'by', 'a', 'fashionable', 'painter', '--', 'ah', ',', 'poor', 'Stroud', '!', 'She', 'thought', 'it', 'the', 'surest', 'way', 'of', 'proclaiming', 'his', 'greatness', '--', 'of', 'forcing', 'it', 'on', 'a', 'purblind', 'public', '.', 'And', 'at', 'the', 'moment', 'I', 'was', '_', 'the', '_', 'fashionable', 'painter', '.', '\"', '\"', 'Ah', ',', 'poor', 'Stroud', '--', 'as', 'you', 'say', '.', 'Was', '_', 'that', '_', 'his', 'history', '?', '\"', '\"', 'That', 'was', 'his', 'history', '.', 'She', 'believed', 'in', 'him', ',', 'gloried', 'in', 'him', '--', 'or', 'thought', 'she', 'did', '.', 'But', 'she', 'couldn', \"'\", 't', 'bear', 'not', 'to', 'have', 'all', 'the', 'drawing-rooms', 'with', 'her', '.', 'She', 'couldn', \"'\", 't', 'bear', 'the', 'fact', 'that', ',', 'on', 'varnishing', 'days', ',', 'one', 'could', 'always', 'get', 'near', 'enough', 'to', 'see', 'his', 'pictures', '.', 'Poor', 'woman', '!', 'She', \"'\", 's', 'just', 'a', 'fragment', 'groping', 'for', 'other', 'fragments', '.', 'Stroud', 'is', 'the', 'only', 'whole', 'I', 'ever', 'knew', '.', '\"', '\"', 'You', 'ever', 'knew', '?', 'But', 'you', 'just', 'said', '--', '\"', 'Gisburn', 'had', 'a', 'curious', 'smile', 'in', 'his', 'eyes', '.', '\"', 'Oh', ',', 'I', 'knew', 'him', ',', 'and', 'he', 'knew', 'me', '--', 'only', 'it', 'happened', 'after', 'he', 'was', 'dead', '.', '\"', 'I', 'dropped', 'my', 'voice', 'instinctively', '.', '\"', 'When', 'she', 'sent', 'for', 'you', '?', '\"', '\"', 'Yes', '--', 'quite', 'insensible', 'to', 'the', 'irony', '.', 'She', 'wanted', 'him', 'vindicated', '--', 'and', 'by', 'me', '!', '\"', 'He', 'laughed', 'again', ',', 'and', 'threw', 'back', 'his', 'head', 'to', 'look', 'up', 'at', 'the', 'sketch', 'of', 'the', 'donkey', '.', '\"', 'There', 'were', 'days', 'when', 'I', 'couldn', \"'\", 't', 'look', 'at', 'that', 'thing', '--', 'couldn', \"'\", 't', 'face', 'it', '.', 'But', 'I', 'forced', 'myself', 'to', 'put', 'it', 'here', ';', 'and', 'now', 'it', \"'\", 's', 'cured', 'me', '--', 'cured', 'me', '.', 'That', \"'\", 's', 'the', 'reason', 'why', 'I', 'don', \"'\", 't', 'dabble', 'any', 'more', ',', 'my', 'dear', 'Rickham', ';', 'or', 'rather', 'Stroud', 'himself', 'is', 'the', 'reason', '.', '\"', 'For', 'the', 'first', 'time', 'my', 'idle', 'curiosity', 'about', 'my', 'companion', 'turned', 'into', 'a', 'serious', 'desire', 'to', 'understand', 'him', 'better', '.', '\"', 'I', 'wish', 'you', \"'\", 'd', 'tell', 'me', 'how', 'it', 'happened', ',', '\"', 'I', 'said', '.', 'He', 'stood', 'looking', 'up', 'at', 'the', 'sketch', ',', 'and', 'twirling', 'between', 'his', 'fingers', 'a', 'cigarette', 'he', 'had', 'forgotten', 'to', 'light', '.', 'Suddenly', 'he', 'turned', 'toward', 'me', '.', '\"', 'I', \"'\", 'd', 'rather', 'like', 'to', 'tell', 'you', '--', 'because', 'I', \"'\", 've', 'always', 'suspected', 'you', 'of', 'loathing', 'my', 'work', '.', '\"', 'I', 'made', 'a', 'deprecating', 'gesture', ',', 'which', 'he', 'negatived', 'with', 'a', 'good-humoured', 'shrug', '.', '\"', 'Oh', ',', 'I', 'didn', \"'\", 't', 'care', 'a', 'straw', 'when', 'I', 'believed', 'in', 'myself', '--', 'and', 'now', 'it', \"'\", 's', 'an', 'added', 'tie', 'between', 'us', '!', '\"', 'He', 'laughed', 'slightly', ',', 'without', 'bitterness', ',', 'and', 'pushed', 'one', 'of', 'the', 'deep', 'arm-chairs', 'forward', '.', '\"', 'There', ':', 'make', 'yourself', 'comfortable', '--', 'and', 'here', 'are', 'the', 'cigars', 'you', 'like', '.', '\"', 'He', 'placed', 'them', 'at', 'my', 'elbow', 'and', 'continued', 'to', 'wander', 'up', 'and', 'down', 'the', 'room', ',', 'stopping', 'now', 'and', 'then', 'beneath', 'the', 'picture', '.', '\"', 'How', 'it', 'happened', '?', 'I', 'can', 'tell', 'you', 'in', 'five', 'minutes', '--', 'and', 'it', 'didn', \"'\", 't', 'take', 'much', 'longer', 'to', 'happen', '.', '.', '.', '.', 'I', 'can', 'remember', 'now', 'how', 'surprised', 'and', 'pleased', 'I', 'was', 'when', 'I', 'got', 'Mrs', '.', 'Stroud', \"'\", 's', 'note', '.', 'Of', 'course', ',', 'deep', 'down', ',', 'I', 'had', 'always', '_', 'felt', '_', 'there', 'was', 'no', 'one', 'like', 'him', '--', 'only', 'I', 'had', 'gone', 'with', 'the', 'stream', ',', 'echoed', 'the', 'usual', 'platitudes', 'about', 'him', ',', 'till', 'I', 'half', 'got', 'to', 'think', 'he', 'was', 'a', 'failure', ',', 'one', 'of', 'the', 'kind', 'that', 'are', 'left', 'behind', '.', 'By', 'Jove', ',', 'and', 'he', '_', 'was', '_', 'left', 'behind', '--', 'because', 'he', 'had', 'come', 'to', 'stay', '!', 'The', 'rest', 'of', 'us', 'had', 'to', 'let', 'ourselves', 'be', 'swept', 'along', 'or', 'go', 'under', ',', 'but', 'he', 'was', 'high', 'above', 'the', 'current', '--', 'on', 'everlasting', 'foundations', ',', 'as', 'you', 'say', '.', '\"', 'Well', ',', 'I', 'went', 'off', 'to', 'the', 'house', 'in', 'my', 'most', 'egregious', 'mood', '--', 'rather', 'moved', ',', 'Lord', 'forgive', 'me', ',', 'at', 'the', 'pathos', 'of', 'poor', 'Stroud', \"'\", 's', 'career', 'of', 'failure', 'being', 'crowned', 'by', 'the', 'glory', 'of', 'my', 'painting', 'him', '!', 'Of', 'course', 'I', 'meant', 'to', 'do', 'the', 'picture', 'for', 'nothing', '--', 'I', 'told', 'Mrs', '.', 'Stroud', 'so', 'when', 'she', 'began', 'to', 'stammer', 'something', 'about', 'her', 'poverty', '.', 'I', 'remember', 'getting', 'off', 'a', 'prodigious', 'phrase', 'about', 'the', 'honour', 'being', '_', 'mine', '_', '--', 'oh', ',', 'I', 'was', 'princely', ',', 'my', 'dear', 'Rickham', '!', 'I', 'was', 'posing', 'to', 'myself', 'like', 'one', 'of', 'my', 'own', 'sitters', '.', '\"', 'Then', 'I', 'was', 'taken', 'up', 'and', 'left', 'alone', 'with', 'him', '.', 'I', 'had', 'sent', 'all', 'my', 'traps', 'in', 'advance', ',', 'and', 'I', 'had', 'only', 'to', 'set', 'up', 'the', 'easel', 'and', 'get', 'to', 'work', '.', 'He', 'had', 'been', 'dead', 'only', 'twenty-four', 'hours', ',', 'and', 'he', 'died', 'suddenly', ',', 'of', 'heart', 'disease', ',', 'so', 'that', 'there', 'had', 'been', 'no', 'preliminary', 'work', 'of', 'destruction', '--', 'his', 'face', 'was', 'clear', 'and', 'untouched', '.', 'I', 'had', 'met', 'him', 'once', 'or', 'twice', ',', 'years', 'before', ',', 'and', 'thought', 'him', 'insignificant', 'and', 'dingy', '.', 'Now', 'I', 'saw', 'that', 'he', 'was', 'superb', '.', '\"', 'I', 'was', 'glad', 'at', 'first', ',', 'with', 'a', 'merely', 'aesthetic', 'satisfaction', ':', 'glad', 'to', 'have', 'my', 'hand', 'on', 'such', 'a', \"'\", 'subject', '.', \"'\", 'Then', 'his', 'strange', 'life-likeness', 'began', 'to', 'affect', 'me', 'queerly', '--', 'as', 'I', 'blocked', 'the', 'head', 'in', 'I', 'felt', 'as', 'if', 'he', 'were', 'watching', 'me', 'do', 'it', '.', 'The', 'sensation', 'was', 'followed', 'by', 'the', 'thought', ':', 'if', 'he', '_', 'were', '_', 'watching', 'me', ',', 'what', 'would', 'he', 'say', 'to', 'my', 'way', 'of', 'working', '?', 'My', 'strokes', 'began', 'to', 'go', 'a', 'little', 'wild', '--', 'I', 'felt', 'nervous', 'and', 'uncertain', '.', '\"', 'Once', ',', 'when', 'I', 'looked', 'up', ',', 'I', 'seemed', 'to', 'see', 'a', 'smile', 'behind', 'his', 'close', 'grayish', 'beard', '--', 'as', 'if', 'he', 'had', 'the', 'secret', ',', 'and', 'were', 'amusing', 'himself', 'by', 'holding', 'it', 'back', 'from', 'me', '.', 'That', 'exasperated', 'me', 'still', 'more', '.', 'The', 'secret', '?', 'Why', ',', 'I', 'had', 'a', 'secret', 'worth', 'twenty', 'of', 'his', '!', 'I', 'dashed', 'at', 'the', 'canvas', 'furiously', ',', 'and', 'tried', 'some', 'of', 'my', 'bravura', 'tricks', '.', 'But', 'they', 'failed', 'me', ',', 'they', 'crumbled', '.', 'I', 'saw', 'that', 'he', 'wasn', \"'\", 't', 'watching', 'the', 'showy', 'bits', '--', 'I', 'couldn', \"'\", 't', 'distract', 'his', 'attention', ';', 'he', 'just', 'kept', 'his', 'eyes', 'on', 'the', 'hard', 'passages', 'between', '.', 'Those', 'were', 'the', 'ones', 'I', 'had', 'always', 'shirked', ',', 'or', 'covered', 'up', 'with', 'some', 'lying', 'paint', '.', 'And', 'how', 'he', 'saw', 'through', 'my', 'lies', '!', '\"', 'I', 'looked', 'up', 'again', ',', 'and', 'caught', 'sight', 'of', 'that', 'sketch', 'of', 'the', 'donkey', 'hanging', 'on', 'the', 'wall', 'near', 'his', 'bed', '.', 'His', 'wife', 'told', 'me', 'afterward', 'it', 'was', 'the', 'last', 'thing', 'he', 'had', 'done', '--', 'just', 'a', 'note', 'taken', 'with', 'a', 'shaking', 'hand', ',', 'when', 'he', 'was', 'down', 'in', 'Devonshire', 'recovering', 'from', 'a', 'previous', 'heart', 'attack', '.', 'Just', 'a', 'note', '!', 'But', 'it', 'tells', 'his', 'whole', 'history', '.', 'There', 'are', 'years', 'of', 'patient', 'scornful', 'persistence', 'in', 'every', 'line', '.', 'A', 'man', 'who', 'had', 'swum', 'with', 'the', 'current', 'could', 'never', 'have', 'learned', 'that', 'mighty', 'up-stream', 'stroke', '.', '.', '.', '.', '\"', 'I', 'turned', 'back', 'to', 'my', 'work', ',', 'and', 'went', 'on', 'groping', 'and', 'muddling', ';', 'then', 'I', 'looked', 'at', 'the', 'donkey', 'again', '.', 'I', 'saw', 'that', ',', 'when', 'Stroud', 'laid', 'in', 'the', 'first', 'stroke', ',', 'he', 'knew', 'just', 'what', 'the', 'end', 'would', 'be', '.', 'He', 'had', 'possessed', 'his', 'subject', ',', 'absorbed', 'it', ',', 'recreated', 'it', '.', 'When', 'had', 'I', 'done', 'that', 'with', 'any', 'of', 'my', 'things', '?', 'They', 'hadn', \"'\", 't', 'been', 'born', 'of', 'me', '--', 'I', 'had', 'just', 'adopted', 'them', '.', '.', '.', '.', '\"', 'Hang', 'it', ',', 'Rickham', ',', 'with', 'that', 'face', 'watching', 'me', 'I', 'couldn', \"'\", 't', 'do', 'another', 'stroke', '.', 'The', 'plain', 'truth', 'was', ',', 'I', 'didn', \"'\", 't', 'know', 'where', 'to', 'put', 'it', '--', '_', 'I', 'had', 'never', 'known', '_', '.', 'Only', ',', 'with', 'my', 'sitters', 'and', 'my', 'public', ',', 'a', 'showy', 'splash', 'of', 'colour', 'covered', 'up', 'the', 'fact', '--', 'I', 'just', 'threw', 'paint', 'into', 'their', 'faces', '.', '.', '.', '.', 'Well', ',', 'paint', 'was', 'the', 'one', 'medium', 'those', 'dead', 'eyes', 'could', 'see', 'through', '--', 'see', 'straight', 'to', 'the', 'tottering', 'foundations', 'underneath', '.', 'Don', \"'\", 't', 'you', 'know', 'how', ',', 'in', 'talking', 'a', 'foreign', 'language', ',', 'even', 'fluently', ',', 'one', 'says', 'half', 'the', 'time', 'not', 'what', 'one', 'wants', 'to', 'but', 'what', 'one', 'can', '?', 'Well', '--', 'that', 'was', 'the', 'way', 'I', 'painted', ';', 'and', 'as', 'he', 'lay', 'there', 'and', 'watched', 'me', ',', 'the', 'thing', 'they', 'called', 'my', \"'\", 'technique', \"'\", 'collapsed', 'like', 'a', 'house', 'of', 'cards', '.', 'He', 'didn', \"'\", 't', 'sneer', ',', 'you', 'understand', ',', 'poor', 'Stroud', '--', 'he', 'just', 'lay', 'there', 'quietly', 'watching', ',', 'and', 'on', 'his', 'lips', ',', 'through', 'the', 'gray', 'beard', ',', 'I', 'seemed', 'to', 'hear', 'the', 'question', ':', \"'\", 'Are', 'you', 'sure', 'you', 'know', 'where', 'you', \"'\", 're', 'coming', 'out', '?', \"'\", '\"', 'If', 'I', 'could', 'have', 'painted', 'that', 'face', ',', 'with', 'that', 'question', 'on', 'it', ',', 'I', 'should', 'have', 'done', 'a', 'great', 'thing', '.', 'The', 'next', 'greatest', 'thing', 'was', 'to', 'see', 'that', 'I', 'couldn', \"'\", 't', '--', 'and', 'that', 'grace', 'was', 'given', 'me', '.', 'But', ',', 'oh', ',', 'at', 'that', 'minute', ',', 'Rickham', ',', 'was', 'there', 'anything', 'on', 'earth', 'I', 'wouldn', \"'\", 't', 'have', 'given', 'to', 'have', 'Stroud', 'alive', 'before', 'me', ',', 'and', 'to', 'hear', 'him', 'say', ':', \"'\", 'It', \"'\", 's', 'not', 'too', 'late', '--', 'I', \"'\", 'll', 'show', 'you', 'how', \"'\", '?', '\"', 'It', '_', 'was', '_', 'too', 'late', '--', 'it', 'would', 'have', 'been', ',', 'even', 'if', 'he', \"'\", 'd', 'been', 'alive', '.', 'I', 'packed', 'up', 'my', 'traps', ',', 'and', 'went', 'down', 'and', 'told', 'Mrs', '.', 'Stroud', '.', 'Of', 'course', 'I', 'didn', \"'\", 't', 'tell', 'her', '_', 'that', '_', '--', 'it', 'would', 'have', 'been', 'Greek', 'to', 'her', '.', 'I', 'simply', 'said', 'I', 'couldn', \"'\", 't', 'paint', 'him', ',', 'that', 'I', 'was', 'too', 'moved', '.', 'She', 'rather', 'liked', 'the', 'idea', '--', 'she', \"'\", 's', 'so', 'romantic', '!', 'It', 'was', 'that', 'that', 'made', 'her', 'give', 'me', 'the', 'donkey', '.', 'But', 'she', 'was', 'terribly', 'upset', 'at', 'not', 'getting', 'the', 'portrait', '--', 'she', 'did', 'so', 'want', 'him', \"'\", 'done', \"'\", 'by', 'some', 'one', 'showy', '!', 'At', 'first', 'I', 'was', 'afraid', 'she', 'wouldn', \"'\", 't', 'let', 'me', 'off', '--', 'and', 'at', 'my', 'wits', \"'\", 'end', 'I', 'suggested', 'Grindle', '.', 'Yes', ',', 'it', 'was', 'I', 'who', 'started', 'Grindle', ':', 'I', 'told', 'Mrs', '.', 'Stroud', 'he', 'was', 'the', \"'\", 'coming', \"'\", 'man', ',', 'and', 'she', 'told', 'somebody', 'else', ',', 'and', 'so', 'it', 'got', 'to', 'be', 'true', '.', '.', '.', '.', 'And', 'he', 'painted', 'Stroud', 'without', 'wincing', ';', 'and', 'she', 'hung', 'the', 'picture', 'among', 'her', 'husband', \"'\", 's', 'things', '.', '.', '.', '.', '\"', 'He', 'flung', 'himself', 'down', 'in', 'the', 'arm-chair', 'near', 'mine', ',', 'laid', 'back', 'his', 'head', ',', 'and', 'clasping', 'his', 'arms', 'beneath', 'it', ',', 'looked', 'up', 'at', 'the', 'picture', 'above', 'the', 'chimney-piece', '.', '\"', 'I', 'like', 'to', 'fancy', 'that', 'Stroud', 'himself', 'would', 'have', 'given', 'it', 'to', 'me', ',', 'if', 'he', \"'\", 'd', 'been', 'able', 'to', 'say', 'what', 'he', 'thought', 'that', 'day', '.', '\"', 'And', ',', 'in', 'answer', 'to', 'a', 'question', 'I', 'put', 'half-mechanically', '--', '\"', 'Begin', 'again', '?', '\"', 'he', 'flashed', 'out', '.', '\"', 'When', 'the', 'one', 'thing', 'that', 'brings', 'me', 'anywhere', 'near', 'him', 'is', 'that', 'I', 'knew', 'enough', 'to', 'leave', 'off', '?', '\"', 'He', 'stood', 'up', 'and', 'laid', 'his', 'hand', 'on', 'my', 'shoulder', 'with', 'a', 'laugh', '.', '\"', 'Only', 'the', 'irony', 'of', 'it', 'is', 'that', 'I', '_', 'am', '_', 'still', 'painting', '--', 'since', 'Grindle', \"'\", 's', 'doing', 'it', 'for', 'me', '!', 'The', 'Strouds', 'stand', 'alone', ',', 'and', 'happen', 'once', '--', 'but', 'there', \"'\", 's', 'no', 'exterminating', 'our', 'kind', 'of', 'art', '.', '\"']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = sorted(set(preprocessed))\n",
        "vocab_size = len(all_words)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlmCgnAwZ4TA",
        "outputId": "06269137-f8be-49a5-b18b-ce0b3faa98e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {token:integer for integer, token in enumerate(all_words)}\n",
        "for i, item in enumerate (vocab.items()):\n",
        "  print(item)\n",
        "  if i>= 50:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r92ImAa6cnT4",
        "outputId": "79e7d80d-4d5a-4a8d-bb1c-ecb1fd7ca2bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n",
            "('A', 11)\n",
            "('Ah', 12)\n",
            "('Among', 13)\n",
            "('And', 14)\n",
            "('Are', 15)\n",
            "('Arrt', 16)\n",
            "('As', 17)\n",
            "('At', 18)\n",
            "('Be', 19)\n",
            "('Begin', 20)\n",
            "('Burlington', 21)\n",
            "('But', 22)\n",
            "('By', 23)\n",
            "('Carlo', 24)\n",
            "('Chicago', 25)\n",
            "('Claude', 26)\n",
            "('Come', 27)\n",
            "('Croft', 28)\n",
            "('Destroyed', 29)\n",
            "('Devonshire', 30)\n",
            "('Don', 31)\n",
            "('Dubarry', 32)\n",
            "('Emperors', 33)\n",
            "('Florence', 34)\n",
            "('For', 35)\n",
            "('Gallery', 36)\n",
            "('Gideon', 37)\n",
            "('Gisburn', 38)\n",
            "('Gisburns', 39)\n",
            "('Grafton', 40)\n",
            "('Greek', 41)\n",
            "('Grindle', 42)\n",
            "('Grindles', 43)\n",
            "('HAD', 44)\n",
            "('Had', 45)\n",
            "('Hang', 46)\n",
            "('Has', 47)\n",
            "('He', 48)\n",
            "('Her', 49)\n",
            "('Hermia', 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Text Tokenizer"
      ],
      "metadata": {
        "id": "uORC2Xxld-PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV1:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab\n",
        "        self.int_to_str = {i: s for s, i in vocab.items()}\n",
        "\n",
        "    def encode(self, text):\n",
        "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
        "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "        ids = [self.str_to_int[s] for s in preprocessed if s in self.str_to_int]\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        text = \" \".join(self.int_to_str[i] for i in ids if i in self.int_to_str)\n",
        "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "urVXLNZadLe9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV1(vocab)\n",
        "text = \"\"\"\"It's the last he painted, you know,\"\n",
        "       Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C42cGgu6e86c",
        "outputId": "f32f3a5a-c451-490b-82c8-1e617adc4b91"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgD7jAAVfRBx",
        "outputId": "863ed463-826f-4764-fa07-b1ab3c0484c0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, do you like tea?\"\n",
        "print(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEdc6G7NfYWF",
        "outputId": "b3551b74-c3c6-4749-be82-0ba3de44b262"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 355, 1126, 628, 975, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = sorted(list(set(preprocessed)))\n",
        "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
        "vocab = {token: integer for integer, token in enumerate(all_tokens)}\n",
        "print(len(vocab.items()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku1OoGoXgXde",
        "outputId": "ea112bdd-7779-4332-903b-661a835d74f1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(list(vocab.items())[-5:]):\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70YgKW42hf5i",
        "outputId": "32ee2037-f965-497e-96be-0bda0eee983a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('younger', 1127)\n",
            "('your', 1128)\n",
            "('yourself', 1129)\n",
            "('<|endoftext|>', 1130)\n",
            "('<|unk|>', 1131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV2:\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = { i:s for s,i in vocab.items()}\n",
        "\n",
        "  def encode(self, text):\n",
        "    preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "    preprocessed = [\n",
        "        item.strip() for item in preprocessed if item.strip()\n",
        "    ]\n",
        "    preprocessed = [item if item in self.str_to_int\n",
        "                    else \"<|unk|>\" for item in preprocessed]\n",
        "    ids = [self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self, ids):\n",
        "    text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "    text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "u8HcX_EqiDyQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"Hello, do you like tea?\"\n",
        "text2 = \"In the sunlit terraces of the palace.\"\n",
        "text = \" <|endoftext|> \".join((text1, text2))\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmrbqGB1i7AH",
        "outputId": "ce1ae9db-8794-4af6-d297-4b6646692219"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV2(vocab)\n",
        "print(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnc6u1kmi_hu",
        "outputId": "22e18280-f3ba-4009-bfd3-a4aac367d3a4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(tokenizer.encode(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFzQAROUNb3z",
        "outputId": "dffca514-45cb-44e3-b696-463354a9813d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BPE"
      ],
      "metadata": {
        "id": "oB757OnWWWQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm_SfV5nNqpH",
        "outputId": "d6c6680c-60c0-4711-ca50-83f05db500b0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m0.1/1.2 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u001b[0m\u001b[91m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "import tiktoken\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nArAjitsQ3kc",
        "outputId": "3a8acfc1-ea5c-4580-94a0-8845a8b8d635"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "tvDWIsjCRInS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\n",
        "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
        "     \"of someunknownPlace.\"\n",
        " )\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w94cxyERPFY",
        "outputId": "b5428ebd-b083-42b4-9b68-55d2aa1e9310"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8eKmdJCRZcs",
        "outputId": "b1a32ea6-6395-4353-ad63-b2be5a695a31"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Sampling with sliding window"
      ],
      "metadata": {
        "id": "1Emv8d1AWOTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(len(enc_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V36cKaLURkNO",
        "outputId": "35a048ba-6fae-4642-9237-b65b48f53d19"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample = enc_text[50:]"
      ],
      "metadata": {
        "id": "-wCtDikOUeWj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 4\n",
        "x = enc_sample[:context_size]\n",
        "y = enc_sample[1:context_size+1]\n",
        "print(f\"x: {x}\")\n",
        "print(f\"y:      {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2YhRvjRUrCB",
        "outputId": "2190198f-5c24-4a78-8180-26490c04a99f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: [290, 4920, 2241, 287]\n",
            "y:      [4920, 2241, 287, 257]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "  print(context, \"---->\", desired)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7EQM9onVE7B",
        "outputId": "019d5e26-9700-4d4b-9e65-d6660ff5f84c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290] ----> 4920\n",
            "[290, 4920] ----> 2241\n",
            "[290, 4920, 2241] ----> 287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size+1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "  print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQru7KYzVfhR",
        "outputId": "8aada2a7-a316-491d-b4b0-14421fcce586"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " and ---->  established\n",
            " and established ---->  himself\n",
            " and established himself ---->  in\n",
            " and established himself in ---->  a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self, txt, tokenizer, max_length, stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(txt)\n",
        "\n",
        "    for i in range(0, len(token_ids) - max_length, stride):\n",
        "      input_chunk = token_ids[i:i+max_length]\n",
        "      target_chunk = token_ids[i+1:i+max_length+1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "Zrffto_kVzsB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=shuffle,\n",
        "      drop_last=drop_last,\n",
        "      num_workers=num_workers\n",
        "  )\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "7WlkpAJzYKSJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "typbYW6caCJQ",
        "outputId": "20a4ded7-2371-4e90-c2b5-0748907c56fe"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch = next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYkK34eOaPB1",
        "outputId": "986c8abf-420d-448d-f8a1-62d379d333bc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"Targets:\\n\", targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP9eoiiyaP__",
        "outputId": "a8dfd105-3e5c-46ac-cb51-5c9bcdae10f3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "Targets:\n",
            " tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Token Embeddings"
      ],
      "metadata": {
        "id": "napEjVef2K39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([2, 3, 5, 1])"
      ],
      "metadata": {
        "id": "GdzKu8iFcJdZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 6\n",
        "output_dim = 3"
      ],
      "metadata": {
        "id": "j5RmrJAW16v2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx6EPAWB2GEE",
        "outputId": "9c5a1d8e-463c-43be-bd98-4b1da32ec1a1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(torch.tensor([3])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw6NWMq62eG5",
        "outputId": "a8f78e19-1a74-4450-90c4-cde8e0b5a8ba"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(input_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDChNzWW2sDa",
        "outputId": "a44346f1-ce12-41ea-b458-e0d9ade9c583"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-2.8400, -0.7849, -1.4096],\n",
            "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embeddings"
      ],
      "metadata": {
        "id": "eWC9-hiKyrFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "f86f4Ccp2-Zl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=8, max_length=max_length,\n",
        "   stride=max_length, shuffle=False\n",
        " )\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Token IDs:\\n\", inputs)\n",
        "print(\"\\nInputs shape:\\n\", inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2EOAGbZy5mH",
        "outputId": "5c244120-3047-4dc6-d8b6-38922fabf763"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Inputs shape:\n",
            " torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqgOw4zizIms",
        "outputId": "cef86168-3c8b-49ed-b67b-53964148b2aa"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
        "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
        "print(pos_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLl2p47Kz2Uc",
        "outputId": "93b313a6-1fed-4600-b09d-5691a6241749"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = token_embeddings + pos_embeddings\n",
        "print(input_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4YN8olt0R0e",
        "outputId": "32862923-f910-4149-c640-49ea4214f47a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6CPFKWSE0fJh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}